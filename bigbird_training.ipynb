{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a7e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (1.18.4)\n",
      "Requirement already satisfied: packaging in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: aiohttp in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: xxhash in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from datasets) (1.4.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from datasets) (7.0.0)\n",
      "Requirement already satisfied: responses<0.19 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: dill in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: multiprocess in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: filelock in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: pyyaml in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from packaging->datasets) (3.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/chang/anaconda3/envs/domain/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479321b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/chang/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0b9791354a49dea941eaab05e38387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "squad = load_dataset(\"squad\")\n",
    "#squad = load_dataset(\"squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de4fb2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BigBirdTokenizerFast\n",
    "import torch\n",
    "\n",
    "tokenizer = BigBirdTokenizerFast.from_pretrained(\"abhinavkulkarni/bigbird-roberta-base-finetuned-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "581f0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=512,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "    \n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f023fe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [65, 1776, 4251, 851, 363, 5384, 5436, 8011, 1757, 388, 1349, 3466, 388, 507, 555, 9007, 4982, 131, 66, 17441, 20322, 112, 363, 1625, 569, 358, 7936, 2196, 114, 418, 4953, 363, 8875, 11920, 439, 3970, 29601, 419, 358, 10962, 15308, 387, 363, 5384, 5436, 114, 34629, 388, 2267, 387, 363, 8875, 11920, 391, 6577, 441, 112, 419, 358, 15418, 15308, 387, 2052, 452, 5202, 611, 49410, 452, 363, 8278, 467, 37623, 679, 1316, 2286, 16644, 2617, 2012, 7507, 385, 363, 8875, 11920, 419, 363, 32621, 4071, 387, 363, 17481, 8995, 114, 34629, 2258, 363, 37893, 4071, 419, 363, 2003, 17732, 112, 358, 38020, 1396, 387, 11544, 391, 14681, 114, 733, 419, 358, 30170, 387, 363, 1137, 17732, 480, 507, 555, 9007, 112, 4982, 911, 363, 5384, 5436, 403, 2097, 49389, 4221, 385, 9382, 6307, 425, 5958, 1507, 29704, 7697, 388, 1349, 3466, 114, 1730, 363, 987, 387, 363, 1489, 3809, 458, 493, 388, 358, 1378, 1728, 427, 20518, 933, 614, 25928, 391, 363, 3662, 31491, 929, 419, 358, 2930, 112, 3761, 7916, 15308, 387, 5436, 114, 66, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'start_positions': 133, 'end_positions': 139}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_squad['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee477a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e45aaef14e4eae9fe0fef3acb253d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8ab77b75654d41ac28281e66bd64dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3ebc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 19:25:37.492232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd8675ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BigBirdForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "model = BigBirdForQuestionAnswering.from_pretrained(\"abhinavkulkarni/bigbird-roberta-base-finetuned-squad\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "563d53d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chang/anaconda3/envs/domain/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 87599\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32850\n",
      "Attention type 'block_sparse' is not possible if sequence_length: 512 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32850' max='32850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32850/32850 1:55:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.946400</td>\n",
       "      <td>0.943572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.886037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.518700</td>\n",
       "      <td>0.967431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-1000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-1000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-1500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-1500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-2000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-2000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-2500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-2500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-3000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-3000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-3500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-3500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-4000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-4000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-4000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-4500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-4500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-5000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-5000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-5000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-5500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-5500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-5500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-6000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-6000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-6000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-6500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-6500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-6500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-7000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-7000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-7000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-7500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-7500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-7500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-8000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-8000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-8000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-8500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-8500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-8500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-9000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-9000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-9000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-9500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-9500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-9500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-10000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-10000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-10000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-10500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-10500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-10500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10570\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-11000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-11000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-11000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-11500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-11500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-11500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-12000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-12000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-12000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-12500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-12500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-12500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-13000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-13000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-13000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-13500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-13500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-13500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-14000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-14000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-14000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-14500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-14500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-14500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-15000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-15000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-15000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-15500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-15500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-15500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-16000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-16000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-16000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-16500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-16500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-16500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-17000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-17000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-17000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-17500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-17500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-17500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-18000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-18000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-18000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-18500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-18500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-18500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-19000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-19000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-19000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-19500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-19500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-19500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-20000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-20000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-20000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-20500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-20500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-20500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-21000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-21000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-21000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-21500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-21500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-21500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10570\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-22000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-22000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-22000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-22500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-22500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-22500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-23000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-23000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-23000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-23500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-23500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-23500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-24000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-24000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-24000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-24500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-24500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-24500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-25000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-25000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-25000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-25500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-25500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-25500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-26000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-26000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-26000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-26500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-26500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-26500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-27000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-27000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-27000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-27500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-27500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-27500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-28000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-28000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-28000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-28500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-28500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-28500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-29000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-29000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-29000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-29500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-29500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-29500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-30000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-30000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-30000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-30500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-30500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-30500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-31000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-31000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-31000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-31500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-31500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-31500/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-32000\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-32000/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-32000/special_tokens_map.json\n",
      "Saving model checkpoint to ./fine_tuned_bigbird/checkpoint-32500\n",
      "Configuration saved in ./fine_tuned_bigbird/checkpoint-32500/config.json\n",
      "Model weights saved in ./fine_tuned_bigbird/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in ./fine_tuned_bigbird/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in ./fine_tuned_bigbird/checkpoint-32500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10570\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=32850, training_loss=0.7782535319567815, metrics={'train_runtime': 6936.3076, 'train_samples_per_second': 37.887, 'train_steps_per_second': 4.736, 'total_flos': 7.24817216479703e+16, 'train_loss': 0.7782535319567815, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fine_tuned_bigbird\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b689b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './fine_bigbird.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "645155d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BigBirdTokenizerFast, BigBirdForQuestionAnswering\n",
    "import torch\n",
    "tokenizer = BigBirdTokenizerFast.from_pretrained(\"abhinavkulkarni/bigbird-roberta-base-finetuned-squad\")\n",
    "model = BigBirdForQuestionAnswering.from_pretrained(\"abhinavkulkarni/bigbird-roberta-base-finetuned-squad\").cuda()\n",
    "model.load_state_dict(torch.load('./fine_bigbird.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525e8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import time\n",
    "\n",
    "bible_data = pandas.read_csv('./bible_summary.csv', header=None)\n",
    "bible_text = bible_data[3].tolist()[1:]\n",
    "\n",
    "context = \"\"\n",
    "for i in range(len(bible_text)):\n",
    "    context += bible_text[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc592178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "exec_time:47.13561sec\n",
      "Obed-Edom\n"
     ]
    }
   ],
   "source": [
    "question = \"Who did the God blessed?\"\n",
    "n = len(context)\n",
    "start = 0\n",
    "maxtorch = 0\n",
    "answer_start = 0\n",
    "answer_end = 0\n",
    "answer = \"\"\n",
    "flag = True\n",
    "index = 0\n",
    "start_time = time.time()\n",
    "while flag:\n",
    "    index += 1\n",
    "    print(index)\n",
    "    end = start + 15000\n",
    "    if end >= n:\n",
    "        flag = False\n",
    "        end = n-1\n",
    "    while True:\n",
    "        if context[end] == \".\" or context[end] == \"?\" or context[end] == \"!\":\n",
    "            break\n",
    "        end -= 1\n",
    "    inputs = tokenizer.encode_plus(question, context[start:end+1], truncation=True, return_tensors='pt')\n",
    "    inputs.to('cuda')\n",
    "    \n",
    "    outputs = model(**inputs)\n",
    "    even = (int(torch.max(outputs[0])) + int(torch.max(outputs[1]))) / 2\n",
    "    if even > maxtorch:\n",
    "        maxtorch = even\n",
    "        answer_start = torch.argmax(outputs[0])  \n",
    "        answer_end = torch.argmax(outputs[1]) + 1\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "    \n",
    "    #answer_start = torch.argmax(outputs[0])  \n",
    "    #answer_end = torch.argmax(outputs[1]) + 1\n",
    "    \n",
    "    #answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "    start = end + 1\n",
    "    if context[start] == \" \":\n",
    "        start += 1\n",
    "end_time = time.time()\n",
    "exec_time = end_time - start_time\n",
    "print(\"exec_time:{:.5f}sec\".format(exec_time))\n",
    "print(answer)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ad755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "domain",
   "language": "python",
   "name": "domain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
