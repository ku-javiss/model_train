{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54b52583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# pd.set_option('display.max_rows',20000)\n",
    "dataset_df = pd.read_csv('/home/chang/domain_intent/domain_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b275c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   verse               domain\n",
      "0      Then all the people of Judah took Uzziah, who ...                bible\n",
      "1      Uzziah was sixteen years old when he became ki...                bible\n",
      "2      The Ammonites gave offerings to Uzziah: and ne...                bible\n",
      "3      Uzziah made towers in Jerusalem, at the doorwa...                bible\n",
      "4      In addition, Uzziah had an army of fighting-me...                bible\n",
      "...                                                  ...                  ...\n",
      "42879  what very will the afghan good be like this we...  NotPlayMusicOrVideo\n",
      "42880             rate this textbook two out of 6 points  NotPlayMusicOrVideo\n",
      "42881  zero that textbook includes two point this sco...  NotPlayMusicOrVideo\n",
      "42882  reduced wins this textbook followed tries out ...  NotPlayMusicOrVideo\n",
      "42883  rate in this critique two pass out views only ...  NotPlayMusicOrVideo\n",
      "\n",
      "[42884 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset_df.columns = ['verse', 'domain']\n",
    "print(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b407b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   verse               domain  \\\n",
      "0      Then all the people of Judah took Uzziah, who ...                bible   \n",
      "1      Uzziah was sixteen years old when he became ki...                bible   \n",
      "2      The Ammonites gave offerings to Uzziah: and ne...                bible   \n",
      "3      Uzziah made towers in Jerusalem, at the doorwa...                bible   \n",
      "4      In addition, Uzziah had an army of fighting-me...                bible   \n",
      "...                                                  ...                  ...   \n",
      "42879  what very will the afghan good be like this we...  NotPlayMusicOrVideo   \n",
      "42880             rate this textbook two out of 6 points  NotPlayMusicOrVideo   \n",
      "42881  zero that textbook includes two point this sco...  NotPlayMusicOrVideo   \n",
      "42882  reduced wins this textbook followed tries out ...  NotPlayMusicOrVideo   \n",
      "42883  rate in this critique two pass out views only ...  NotPlayMusicOrVideo   \n",
      "\n",
      "       label  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n",
      "...      ...  \n",
      "42879      2  \n",
      "42880      2  \n",
      "42881      2  \n",
      "42882      2  \n",
      "42883      2  \n",
      "\n",
      "[42884 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# condition_list = [\n",
    "#     (dataset_df['domain'] == 'bible'),\n",
    "#     (dataset_df['domain'] == 'PlayMusicOrVideo'),\n",
    "#     (dataset_df['domain'] == 'NotPlayMusicOrVideo')\n",
    "# ]\n",
    "# choice_list = [int(0),int(1),int(2)]\n",
    "#dataset_df['label'] = [0 if y == 'not bible' else 1 for y in dataset_df['domain']]\n",
    "\n",
    "def func(x):\n",
    "    if x == 'bible':\n",
    "        return 0\n",
    "    elif x == 'PlayMusicOrVideo':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "# dataset_df['label'] = [0 if y == 'bible' for y in dataset_df['domain']]\n",
    "# dataset_df['label'] = np.select(condition_list,choice_list,default='none')\n",
    "dataset_df['label'] = dataset_df['domain'].apply(lambda x : func(x))\n",
    "print(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8794a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset_df['label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f441f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BertConfig\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae5f6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     verse\n",
      "domain              label data_type       \n",
      "NotPlayMusicOrVideo 2     train      10452\n",
      "                          val         4480\n",
      "PlayMusicOrVideo    1     train      10449\n",
      "                          val         4479\n",
      "bible               0     train       9117\n",
      "                          val         3907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(dataset_df.index.values, \n",
    "                                                  dataset_df.label.values, \n",
    "                                                  test_size=0.3, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=dataset_df.label.values)\n",
    "\n",
    "dataset_df['data_type'] = ['not_set']*dataset_df.shape[0]\n",
    "\n",
    "dataset_df.loc[X_train, 'data_type'] = 'train'\n",
    "dataset_df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "print(dataset_df.groupby(['domain', 'label', 'data_type']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e70cfd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/chang/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)\n",
    "                                          \n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    dataset_df[dataset_df.data_type=='train'].verse.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    dataset_df[dataset_df.data_type=='val'].verse.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(dataset_df[dataset_df.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(dataset_df[dataset_df.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2621c604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(dataset_df[dataset_df.data_type=='train'].label.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4580b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bible': 0, 'PlayMusicOrVideo': 1, 'NotPlayMusicOrVideo': 2}\n"
     ]
    }
   ],
   "source": [
    "label_dict = { 'bible': 0, 'PlayMusicOrVideo': 1 ,'NotPlayMusicOrVideo': 2}\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "832f03c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10f0a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ba787bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chang/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)\n",
    "                  \n",
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "523de62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9303fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619912fd75374836829310dd57a9a43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.10879718167340349\n",
      "Validation loss: 0.047199962315324084\n",
      "F1 Score (Weighted): 0.9863205933481125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.024022240309477152\n",
      "Validation loss: 0.04890045393286498\n",
      "F1 Score (Weighted): 0.9889642577602874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.01044654968608812\n",
      "Validation loss: 0.0511478285286642\n",
      "F1 Score (Weighted): 0.9891949000014741\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.003983536133969079\n",
      "Validation loss: 0.04715476500744401\n",
      "F1 Score (Weighted): 0.9912166346358416\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.0017698824547346002\n",
      "Validation loss: 0.04920106850379674\n",
      "F1 Score (Weighted): 0.9912166984222613\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "    \n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "    \n",
    "    torch.save(model.state_dict(), f'/home/chang/domain_intent/finetuned_BERT_epoch_{epoch}.model')\n",
    "    \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e8a5326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad_sent = pad_sequences([embedding_tokens], maxlen=256, dtype='long', truncating='post', padding='post')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "def Bert_tokenizer(sent):\n",
    "    \n",
    "    bert_sent = '[CLS] ' + sent + ' [SEP]'\n",
    "    tokenized_text = tokenizer.tokenize(bert_sent)\n",
    "    \n",
    "    embedding_tokens = []\n",
    "    for text in tokenized_text:\n",
    "        encoded_sent = tokenizer.convert_tokens_to_ids(text)\n",
    "        embedding_tokens.append(encoded_sent)\n",
    "    \n",
    "    return embedding_tokens\n",
    "\n",
    "def pad_sentences(sent, max_len=256):\n",
    "    embedding_sent = pad_sequences([sent], maxlen=256, dtype='long', truncating='post', padding='post')\n",
    "    return embedding_sent\n",
    "\n",
    "def create_masks(sent):\n",
    "    masks = []\n",
    "    for token in sent:\n",
    "        mask = [float(t>0) for t in token]\n",
    "        masks.append(mask)\n",
    "    return masks\n",
    "\n",
    "def convert_data(sent):\n",
    "    tokenized_sent = Bert_tokenizer(sent)\n",
    "    padded_sent = pad_sentences(tokenized_sent)\n",
    "    \n",
    "    masks_sent = create_masks(padded_sent)\n",
    "    \n",
    "    inputs = torch.tensor(padded_sent)\n",
    "    masks = torch.tensor(masks_sent)\n",
    "    \n",
    "    return inputs, masks\n",
    "\n",
    "def test_sentences(sent):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    print('test_sentences')\n",
    "    inputs, masks = convert_data(sent)\n",
    "    print('convert_data')\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    \n",
    "    logits = F.softmax(outputs[0], dim=1)\n",
    "    logits = logits.cpu().numpy()\n",
    "    print(logits)\n",
    "    print(type(logits))\n",
    "    print(logits.shape)\n",
    "    pred = np.argmax(logits)\n",
    "    print(logits[0][pred]*100)\n",
    "    if pred == 0:\n",
    "        result = \"bible\"\n",
    "    elif pred == 1:\n",
    "        result = \"PlayMusicOrVideo\"\n",
    "    else:\n",
    "        result = \"general QA\"\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac1e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"How's the weather?\"\n",
    "print(test_sentences(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6250e65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_sentences\n",
      "convert_data\n",
      "[[3.3054344e-05 9.9975544e-01 2.1149062e-04]]\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 3)\n",
      "99.97554421424866\n",
      "PlayMusicOrVideo\n",
      "time : 0.017194509506225586\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "sent = \"play a video of Chansung Jung and Volkanovsky\"\n",
    "print(test_sentences(sent))\n",
    "# label = test_sentences(sent)\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "685e54b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_sentences\n",
      "convert_data\n",
      "[[1.7874794e-03 4.4552161e-04 9.9776697e-01]]\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 3)\n",
      "99.77669715881348\n",
      "general QA\n",
      "time : 0.037783145904541016\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "sent = \"what is machine learning?\"\n",
    "print(test_sentences(sent))\n",
    "# label = test_sentences(sent)\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc6ef232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_sentences\n",
      "convert_data\n",
      "[[0.03219715 0.00134538 0.9664574 ]]\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 3)\n",
      "96.64574265480042\n",
      "general QA\n",
      "time : 0.013893604278564453\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "sent = \"What does the word Israel mean?\"\n",
    "print(test_sentences(sent))\n",
    "# label = test_sentences(sent)\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deec707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
